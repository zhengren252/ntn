模组二：信息源爬虫 (Info Crawler Module)
核心设计理念
●口语化说明: 这份蓝图是我们整个项目的顶层设计。核心思想是“化整为零，分而治之”。我们把一个复杂的交易系统，拆分成8个可以独立开发、测试和升级的“积木块”（模组）。它们之间通过一个高效的“信使系统”（消息总线）来沟通，既能协同作战，又互不干扰。这种方式能大大加快开发速度，降低维护成本，而且对服务器要求不高，非常适合初期预算有限的团队。
●技术选型:
○模块间通信: ZeroMQ (PUB/SUB, REQ/REP模式)，实现低延迟、高吞吐量的异步消息传递。
○数据序列化: JSON (易于调试) 或 Protocol Buffers (性能更优)，确保高效、规范的数据交换。
○缓存与状态存储: Redis，用于存储实时状态、市场数据和作为轻量级消息队列。
○持久化存储: SQLite，实现零配置、文件型数据库，满足轻量级部署需求。
○部署: Docker & Docker Compose，实现一键部署和环境隔离。
○核心AI集成: 深度融合 TradingAgents-CN v3.0 的能力，减少重复开发。
全局规范
1. 数据隔离与环境管理规范 (V1.0 新增)
●口语化说明: 这是我们项目的数据“安全法”。为了防止开发时的测试数据污染了真实的生产环境，我们设立了三套独立的环境：development（开发）、staging（准生产/测试）、production（生产）。每套环境都有自己独立的数据库和配置，就像三个互不相通的房间，确保万无一失。
规范项	具体内容	注释
环境定义	系统必须包含三个环境：development, staging, production。	通过环境变量 APP_ENV 进行切换。
配置管理	1. 严禁硬编码：任何密钥、密码、URL等敏感信息严禁写入代码。 <br> 2. 分环境配置：使用不同的配置文件，如 config/base.yaml, config/prod.yaml。程序根据 APP_ENV 加载相应配置。 <br> 3. 密钥注入：API Key等绝密信息通过Docker的环境变量 (-e 或 env_file) 注入容器。	这是隔离硬数据的核心手段。
占位数据	1. 仅限开发环境：所有Mock数据、模拟API响应等占位数据，必须通过 if APP_ENV == 'development': 的逻辑判断进行加载。 <br> 2. 严禁入库：占位数据不允许被写入任何 staging 或 production 的数据库/缓存。	从源头上杜绝占位数据污染。
开发数据	1. 独立数据库：每个环境使用独立的数据库文件（如 dev.db, prod.db）和Redis数据库实例。 <br> 2. 数据清理：development 和 staging 环境应有配套的数据清理脚本，方便一键重置到干净状态。 <br> 3. 数据同步：严禁将生产数据库直接拷贝到开发环境。如需测试，应对数据进行脱敏后方可使用。	隔离与生产无关的数据。
日志规范	development 环境日志级别为 DEBUG；production 环境为 INFO，错误日志需额外输出到独立文件或日志服务。	避免生产环境产生大量无关日志。
2. 系统级集成流程
●口语化说明: 这是整个系统的工作流程图。从“雷达站”（扫描器）发现目标开始，信息会像流水线一样，依次流经“参谋部”（策略优化）、“前线指挥部”（交易员）、“政委”（风控）和“后勤部”（财务），最终由“总司令”（总控）进行全局把控。
sequenceDiagram
    participant S as 扫描器
    participant O as 策略优化
    participant T as 交易员
    participant R as 风控
    participant F as 财务
    participant A as API工厂
    participant M as 总控

    M->>S: 命令: 开始扫描
    S->>A: 请求: 市场行情
    A-->>S: 响应: 行情数据
    S-->>O: 推送: 发现潜在交易对 (ZMQ PUB/SUB)
    O->>A: 请求: 历史K线
    A-->>O: 响应: K线数据
    O-->>T: 推送: 优化后的策略参数包 (ZMQ PUB/SUB)
    T->>R: 请求: 交易风险评估 (ZMQ REQ/REP)
    R-->>T: 响应: 风险评分(3.1)
    T->>F: 请求: 预算申请(含风险分) (ZMQ REQ/REP)
    F-->>T: 响应: 批准资金($48)
    T->>A: 请求: 执行TWAP订单
    A-->>T: 响应: 订单成功
    loop 状态上报
        T->>M: 上报: 持仓状态 (写入Redis)
        R->>M: 上报: 风险指标 (写入Redis)
        F->>M: 上报: 资金状况 (写入Redis)
    end
手册导读
●致项目经理: 本手册是为分布式团队协作而设计的。请将 第一部分 分发给所有开发人员，并将 第二部分 中对应的“模组开发套件”分发给相应的开发团队。
●致开发人员: 请首先仔细阅读 第一部分 以理解项目全局架构和通用规范。然后，深入研究您负责的模组在 第二部分 中的具体开发套件，它将是您日常开发工作的核心指南。
通用开发者指南 (所有团队必读)
1. 系统总体架构
●核心理念: 系统采用微服务架构，由8个高内聚、低耦合的独立模组构成。各模组作为独立的Docker容器运行，通过一个名为ZeroMQ的轻量级消息总线进行异步通信。
●架构图:
●数据流:
○扫描器发现机会，推送到“预备池”。
○策略优化从“预备池”获取机会，进行回测，通过后生成“参数包”推送到“交易池”。
○交易员从“交易池”获取“参数包”，依次向风控和财务申请评估与资金。
○审批通过后，交易员通过API工厂执行交易。
○所有模组的运行状态都实时上报至Redis，由总控进行全局监控和决策。
2. 通信协议与接口规范
●通信技术: ZeroMQ。它不是一个传统的队列，而是一个高性能的通信库。
●通信模式:
○发布/订阅 (PUB/SUB): 用于一对多的广播式通信。例如，扫描器（PUB）发布一个新机会，多个策略优化模组（SUB）都可以收到。
○请求/响应 (REQ/REP): 用于一对一的服务调用。例如，交易员（REQ）向风控（REP）请求风险评分。
●ZeroMQ主题 (Topics) 命名规范: [模组来源].[类别].[具体内容]，例如 scanner.pool.preliminary。
●数据序列化格式: 全系统统一使用 JSON 格式进行数据交换，所有JSON消息必须包含schema_version字段，便于未来升级。
3. 数据隔离与环境管理规范
●核心要求: 所有模组的开发都必须严格遵守本规范，以确保开发、测试和生产环境的绝对隔离。
●规范详情:
规范项	具体内容	注释
环境定义	系统必须包含三个环境：development, staging, production。	通过环境变量 APP_ENV 进行切换。
配置管理	1. 严禁硬编码：任何密钥、密码、URL等敏感信息严禁写入代码。 <br> 2. 分环境配置：使用不同的配置文件，如 config/base.yaml, config/prod.yaml。程序根据 APP_ENV 加载相应配置。 <br> 3. 密钥注入：API Key等绝密信息通过Docker的环境变量 (-e 或 env_file) 注入容器。	这是隔离硬数据的核心手段。
占位数据	1. 仅限开发环境：所有Mock数据、模拟API响应等占位数据，必须通过 if APP_ENV == 'development': 的逻辑判断进行加载。 <br> 2. 严禁入库：占位数据不允许被写入任何 staging 或 production 的数据库/缓存。	从源头上杜绝占位数据污染。
开发数据	1. 独立数据库：每个环境使用独立的数据库文件（如 dev.db, prod.db）和Redis数据库实例。 <br> 2. 数据清理：development 和 staging 环境应有配套的数据清理脚本，方便一键重置到干净状态。 <br> 3. 数据同步：严禁将生产数据库直接拷贝到开发环境。如需测试，应对数据进行脱敏后方可使用。	隔离与生产无关的数据。
日志规范	development 环境日志级别为 DEBUG；production 环境为 INFO，错误日志需额外输出到独立文件或日志服务。	避免生产环境产生大量无关日志。
4. 部署与集成规范
●容器化: 每个模组都必须提供一个 Dockerfile，用于构建其独立的运行镜像。
●集成编排: 项目根目录提供一个 docker-compose.yml 文件，用于一键启动和编排所有模组服务。
●docker-compose.yml 结构示例:
version: '3.8'
services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"

  zmq_broker: # 如果需要一个中心化的代理
    # ...

  api_factory:
    build: ./api_factory
    env_file: .env.prod # 通过env文件注入密钥
    environment:
      - APP_ENV=production
    ports:
      - "8000:8000"

  scanner:
    build: ./scanner
    environment:
      - APP_ENV=production
    depends_on:
      - redis
      - api_factory
  # ... 其他模组

各模组独立开发套件
信息源爬虫 (Info Crawler Module) 开发套件
●2.1 模组概述: 您是系统的“情报搜集员”。您的任务是从各种没有标准API的网站和社交媒体频道（如SEC官网、Telegram）抓取关键信息，清洗、格式化后，广播给全系统。
●2.2 接口契约 (Interaction Contracts)
○调用的服务 (Services Consumed):
■服务: Telegram API等（可能需要通过API统一管理工厂调用）。
○发布的通知 (Notifications Published):
■通信方式: ZeroMQ (PUB)。
■主题: crawler.news。
■消息内容: 发布所有经过清洗和结构化的新闻、公告、社交媒体信息。
■数据结构: {"source": "telegram", "channel": "...", "content": "...", "timestamp": 1672531200, "schema_version": "1.1"}
●2.3 需求书、实施计划、搭建规范: 
●口语化说明: 这是系统的“情报搜集员”。专门负责从那些没有提供标准API的渠道（如某些新闻网站、Telegram频道）抓取信息。它把非结构化的情报变成标准化的数据，供其他AI模组分析使用。
1. 需求书 (Requirements Document)
字段	值	说明
ID	info-crawler-module	模块唯一标识
Version	1.1	版本号
Description	抓取无API的信息源，如新闻网站、社交媒体频道，并将其结构化后分发。	模块核心职责
Features	[{"id":"feat-01", "name":"网站爬虫", "desc":"抓取指定网站（如SEC官网）的HTML内容。"}, {"id":"feat-02", "name":"Telegram监听", "desc":"实时监控指定Telegram频道的上币、预警信息。"}, {"id":"feat-03", "name":"数据清洗与格式化", "desc":"将抓取到的非结构化数据，转换为统一的JSON格式。"}, {"id":"feat-04", "name":"数据分发", "desc":"通过消息总线将处理好的数据推送给需要的模组。"}]	核心功能列表 (JSON格式)
Dependencies	["api-factory-module"]	可能需要通过API工厂调用Telegram等服务的API
2. 实施计划 (Implementation Plan)
阶段	任务	预估工时	产出物
第一周	爬虫框架搭建 (Scrapy/Playwright)	20小时	可抓取静态网页的爬虫原型
第二周	Telegram监听模块开发	20小时	可接收并过滤TG消息的脚本
第三周	数据清洗、校验与分发逻辑	15小时	统一、可靠的数据输出管道
第四周	部署与监控	15小时	稳定运行的爬虫服务
3. 搭建规范 (Construction Specification)
规范项	具体内容	注释
语言/框架	Python (Scrapy, Telethon)	Scrapy负责网页抓取，Telethon负责Telegram
代码结构	crawler/ <br> ├── spiders/ <br> │ └── sec_spider.py <br> ├── telegram_listener.py <br> ├── pipelines.py <br> └── config/	功能分离，便于维护
通信协议	ZeroMQ (PUSH)	将处理好的数据推送到 crawler.news 等主题
数据结构	{"source": "telegram", "channel": "...", "content": "...", "timestamp": 1672531200, "schema_version": "1.0"}	增加schema版本，便于未来升级
部署	Dockerfile	容器化部署
反爬策略	使用代理IP池、随机User-Agent、请求头轮换	提高爬虫的存活率
错误处理	失败重试机制（如3次）、错误日志记录、数据校验失败告警	保证系统的健壮性

